<!--
Copyright (c) 2025 Fabio C.

This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (CC BY-NC-ND 4.0).
See LICENSE-PAPER.md for details.
--> 
# AI-Assisted Development: A Human-Led Approach

## Abstract

This paper introduces a structured two-document framework designed to foster effective collaboration between human developers and AI coding assistants. By clearly separating strategic decision-making (documented in **DECISIONS.md**) from tactical learning artifacts (documented in **LEARNINGS.md**), development teams can harness AI-generated code suggestions without sacrificing architectural coherence or institutional knowledge. The framework is validated in the context of the **WallpaperScraper** project, where DECISIONS.md captured high-level design choices and LEARNINGS.md recorded iterative improvements and pitfalls. Notably, Copilot spontaneously created several debugging and site investigation scripts to troubleshoot issues encountered during service setup, highlighting the AI's operational role beyond code generation. The paper also details formal recommendations for configuring GitHub Copilot at both the repository and user/workspace levels, including sample implementation files and a comparison of the two approaches. Findings underscore the efficacy of governed human–AI collaboration, showing reduced architecture-related code review feedback, minimized downtime following external site changes, bolstered developer confidence, and extensive AI-generated contributions under minimal human supervision. **99.8%** of the WallpaperScraper codebase was generated by the AI assistant, illustrating the framework’s capacity to leverage AI productivity while maintaining essential human oversight and creativity.

## Introduction

Recent advances in machine learning have led to the emergence of AI-driven code completion tools such as GitHub Copilot, which can suggest entire function implementations based on natural language prompts or partial code context. Empirical studies report productivity gains ranging from roughly 20% to over 50% in developer workflows when using such AI pair-programming assistants. Despite these benefits, teams often encounter challenges in integrating AI suggestions into established codebases while preserving architectural standards and project-specific conventions. This paper addresses these gaps by presenting a human-led governance model for AI contributions. By treating the AI as a specialized member of the development team—one tasked with implementation within pre-approved boundaries—we aim to maximize productivity gains while minimizing the risk of architectural drift and knowledge loss.

## Problem Definition

Although AI coding assistants can accelerate routine tasks, they may introduce inconsistencies when suggestions deviate from established project patterns. Without explicit guardrails, developers might inadvertently accept suboptimal or misaligned code snippets, leading to fragmented architectures and increased technical debt. Additionally, teams lack systematic mechanisms to capture *why* certain AI-generated solutions succeeded or failed, resulting in repeated mistakes and lost institutional memory. Finally, unclear role definitions can foster over-reliance on either human intuition or AI automation, undermining effective collaboration. Thus, a structured framework is required to balance human strategic vision with automated implementation support.

### Illustration: Real-World Developer Complaints

Recent discussions in developer communities highlight recurring pain points with AI coding assistants such as GitHub Copilot. Common complaints include:

* **Architectural drift:** AI-generated code often ignores project-specific architecture or coding standards, resulting in inconsistent or unmaintainable code (Reddit, 2023a).
* **Repeated mistakes:** Copilot can repeat past errors or suggest insecure/deprecated patterns, especially when lacking project context (Reddit, 2023a; Hacker News, 2022).
* **Subtle bugs and security risks:** The AI may introduce bugs or vulnerabilities because it lacks full understanding of project intent and constraints (Reddit, 2023a).
* **Loss of institutional knowledge:** Lessons learned and fixes are not captured, so the same mistakes recur and onboarding new contributors becomes harder (Reddit, 2023a).
* **Overwhelming suggestions:** AI can flood the editor with irrelevant or low-quality code, making it harder to focus or find the right solution (Reddit, 2023a).
* **Lack of rationale in suggestions:** AI-generated code often lacks context or comments explaining the approach, making it difficult to review or maintain (Reddit, 2023a).

These issues are echoed across forums, where developers express frustration with the lack of project awareness, context, and knowledge retention in current AI coding tools (Reddit, 2023a, 2023b; Hacker News, 2022). This evidences the need for a governance approach that keeps AI contributions aligned with project architecture and captures learning for future reuse.

## Literature Review

The intersection of human expertise and AI assistance in software development has been the subject of increasing scholarly attention. **AI Pair-Programming and Developer Productivity:** Studies have demonstrated that AI coding assistants can significantly improve developer productivity. In a controlled experiment, developers using GitHub Copilot completed a coding task more than 50% faster than those without it. Field evaluations in corporate settings similarly report sizable efficiency gains: at a large bank, Copilot users achieved on average a 40–50% reduction in task completion time, with junior developers seeing the largest improvements (Chatterjee et al., 2024), and a study of over 400 developers found consistent acceptance of Copilot suggestions (about 33% of suggestions, covering \~20% of total code) along with higher satisfaction and faster coding for boilerplate tasks (Bakal et al., 2025). These productivity benefits, however, come with caveats. *New types of errors*: Researchers have observed that AI suggestions can introduce mistakes or insecure code that developers might overlook, necessitating vigilant human review. Vaithilingam et al. (2022) found that while AI code generation tools accelerate development, they also produce errors or “hallucinated” code that requires additional debugging and validation. Bird, Zimmermann, and Nagappan (2022) emphasize the need for frameworks that tightly integrate human judgment with automated suggestions to mitigate such risks and maintain code quality. Indeed, one empirical study asked whether Copilot is an “asset or liability” for developers—finding that it can be both: a valuable accelerator, but one that occasionally suggests vulnerable code if not guided properly (Moradi Dakhel et al., 2023). These works underscore the importance of managing AI contributions within a structured oversight mechanism.

**Human–AI Collaboration and Trust:** The effectiveness of AI-assisted development depends on how well human developers and AI systems collaborate. Denny et al. (2023) explored the impact of Copilot on student programmers’ learning outcomes, highlighting that maintaining human oversight is crucial to ensure code quality and that students still learn the intended concepts. In professional settings, developers often struggle with trust and code comprehension issues when using AI partners (Finnie-Ansley *et al.*, 2023; Wang *et al.*, 2024). For example, Prather *et al.* (2023) observed that novice programmers were both amazed and confused by Copilot’s suggestions—exclaiming “it’s weird that it knows what I want”—and sometimes accepted suggestions without fully understanding them, reinforcing the need for proper guidance. Wang *et al.* (2024) conducted in-depth interviews and interface design probes, identifying challenges in building appropriate trust with AI coding tools: developers need clear expectations of the AI’s capabilities, the ability to configure its behavior, and transparency to validate its suggestions. Without these, trust in AI assistants can be fragile or misplaced. More broadly, Jarrahi (2018) discusses human–AI symbiosis in organizational decision-making, emphasizing that AI tools excel at speed and pattern recognition while humans contribute contextual understanding and creative problem-solving. The notion of AI *pair programming* has been heralded as a new era of software development (Microsoft Research, 2023), but real-world experience shows it requires well-defined roles and processes to be effective. Collectively, the literature suggests that human creativity and oversight must complement machine efficiency; clearly defined boundaries and collaboration protocols are needed so that developers remain in control and can leverage the AI as a cooperative partner rather than a confusing oracle.

**Architectural Governance and Knowledge Retention:** Foundational software engineering research highlights the importance of preserving design rationale and project knowledge to guide future development. In the realm of software architecture, practitioners have long advocated for recording architecture decisions to maintain system integrity over time (Tyree & Akerman, 2005; Nygard, 2011). Architecture Decision Records (ADRs) provide a lightweight mechanism for capturing the context, decision, and consequences of key design choices, preventing knowledge from residing only in individual developers’ heads. Henderson (2023) and other industry sources have made templates and examples widely available to promote ADR adoption in projects. Such practices align with the concept of “living documentation,” where documentation is continuously updated alongside the code (Martraire, 2019). Indeed, the value of systematic knowledge management in software teams has been recognized for decades (IEEE Software, 2002). Effective knowledge retention—through mechanisms like post-mortems, lessons learned repositories, and up-to-date documentation—helps teams avoid repeating mistakes and eases the onboarding of new members. Milton and Lambe (2019) emphasize that social knowledge sharing and collaboration are key to a learning organization; in a software context, this translates to making tacit developer knowledge explicit and accessible. In summary, prior work suggests that combining rigorous architectural governance with continuous knowledge capture can significantly improve long-term software quality and team productivity. This paper builds on these insights by proposing a framework that integrates AI assistance into such governance and documentation practices, ensuring that AI contributions are both guided by, and contributors to, the project’s architectural knowledge base.

## Project Overview

The WallpaperScraper project serves dual purposes:

1. **Practical Utility**: A Python tool that downloads ultra-high-resolution wallpapers from multiple reputable sources, with robust configuration and quality assurance, for use as digital backgrounds or for other display needs.
2. **Research Platform**: An experimental testbed for human-AI collaborative software development, validating a two-document governance framework (DECISIONS.md and LEARNINGS.md) for AI-assisted coding.

### Supported Sites and Configuration

The current version supports the following wallpaper sites (see also `SITES.md`):
- wallpaperswide.com
- wallhaven.cc
- wallpaperbat.com

Several sites are now deprecated due to structural changes or anti-scraping measures (e.g., 4kwallpapers.com, wallpapercave.com, wallpapers.com/widescreen, ultrawidewallpapers.net).

All configuration is centralized in `config.py`, including:
- `RESOLUTION`: Desired wallpaper size (e.g., '5120x1440')
- `THEMES`: List of search themes (e.g., ['nature', 'abstract', 'space'])
- `SITES`: List of enabled wallpaper sites
- Output and temp folder paths
- HTTP and parallelism settings

### Key Features
- Fetches wallpapers by theme from multiple sources
- Sophisticated resolution verification (exact match, similar aspect, larger, insufficient)
- Parallel downloads with retry and exponential backoff
- Robust error handling and detailed logging
- Adaptive scraping logic with fallback selectors and browser-like headers
- Clean, centralized configuration
- Designed for Windows PowerShell

### Debugging and Site Structure Investigation Scripts

Several debugging and site investigation scripts were created spontaneously by Copilot to troubleshoot issues encountered during service setup and adaptation to changing website structures. These scripts were not part of the original design, but emerged as practical tools to ensure robust scraping and rapid response to site changes:
- `debug_site_structure.py`: Probes a target page, prints out findings, and tries multiple selectors to discover wallpaper links and download URLs.
- `investigate_wallpaperswide.py`: Analyzes wallpaperswide.com using multiple approaches (by resolution, category, homepage), saves HTML for inspection, and documents effective selectors.
- `investigate_wallpapers.py`: Focuses on 4kwallpapers.com (now deprecated), reverse-engineering navigation and download structure for robust scraper implementation.

These scripts are essential for adapting to site changes, onboarding new contributors, and documenting the rationale behind scraping strategies. Their spontaneous creation by Copilot highlights the AI's role not only in implementation, but also in problem-solving and operational resilience during the development process.

## The Two-Document Framework: DECISIONS.md and LEARNINGS.md

The project is governed by two living documents:

- **DECISIONS.md**: The authoritative record of architectural and strategic choices. All architectural changes must be consistent with this file, and no changes are made without explicit human approval. This file documents module structure, configuration, service plugin architecture, and quality standards (e.g., the four-level resolution classification system).
- **LEARNINGS.md**: The dynamic knowledge base of implementation learnings, optimizations, and failures. All significant insights, optimizations, and failures are automatically documented here, supporting continuous improvement and knowledge sharing. This file is referenced before making suggestions, to avoid repeating past mistakes and to build on existing solutions.

This framework ensures that the AI assistant (GitHub Copilot) operates within clear boundaries, always consulting DECISIONS.md before proposing or making any architectural or strategic changes, and documenting all significant learnings in LEARNINGS.md. The human lead retains strategic oversight, while the AI acts as a highly productive implementation partner.

### Enforcement via Copilot Instructions

The repository includes `.github/copilot-instructions.md`, which encodes the following rules (see file for full details):
- Always consult `DECISIONS.md` before proposing or making any architectural or strategic changes.
- Do not suggest changes that contradict `DECISIONS.md` unless explicitly instructed by a human contributor.
- Do not make changes to `PAPER.md` without explicit user consent.
- All significant implementation learnings, optimizations, and failures must be documented in `LEARNINGS.md`.
- Use `LEARNINGS.md` as a reference to inform suggestions, avoid previously encountered issues, and build upon existing solutions.
- Adhere to Microsoft Azure best practices for Azure-related code and operations.

These instructions are enforced at the repository level, ensuring that all contributors and the AI assistant follow the same governance model. The AI is also required to use Azure best practices and tools when generating Azure-related code or operations.

## Implementation Strategy and Roles

A clear division of roles between the human developer(s) and the AI assistant is central to our framework:

* **Human Role – Development Lead:** The human lead (or a group of senior developers) defines the overarching architecture and project goals. They create and initially populate DECISIONS.md with the fundamental design decisions and constraints at project inception. During development, they review any proposed changes to DECISIONS.md (for instance, if the AI or a team member suggests a new architecture approach) and ensure such changes align with long-term vision and best practices. The human lead also monitors LEARNINGS.md updates for accuracy and relevance. In short, the human retains strategic oversight, ensuring that the project adheres to its intended architecture, meets quality standards, and incorporates industry best practices or organizational policies.

* **AI Role – Implementation Assistant:** GitHub Copilot (or a similar AI coding assistant) acts as an on-demand implementation partner. Its primary task is to generate code snippets, functions, and even entire modules in line with the guidelines set forth in DECISIONS.md. When encountering an ambiguous task or a high-level request from the developer, the AI will consult the context of DECISIONS.md (which is provided to it; see next section on tool integration) to ensure compliance with architectural decisions. After implementing a solution or when a significant event occurs (e.g., a tricky bug fix or a new optimization), the AI is expected to append an entry to LEARNINGS.md summarizing the issue and outcome, subject to the human lead’s review. In doing so, the AI effectively documents its thought process and the rationale behind its code suggestions, building a trail of “AI thought” that the human can audit. This symbiotic workflow allows a substantial portion of the code to be written by the AI, while the human focuses on guiding the AI and curating the knowledge the AI produces.

Under this model, the AI assistant becomes a highly productive junior developer that works at scale, but always under the mentorship and direction of the human lead. The **WallpaperScraper** project exemplified this: by project’s end, an estimated 99.8% of the code was AI-generated under the governance of DECISIONS.md and LEARNINGS.md. The human lead only needed to intervene to adjust minor details and make judgment calls on strategic matters. Creative problem-solving and critical thinking remained **indispensable** human contributions—particularly in interpreting the framework (e.g., deciding when a new ADR was needed) and ensuring quality and coherence of the overall system.

## Case Study: The WallpaperScraper Project

The WallpaperScraper project implements the two-document framework from inception. The codebase is organized as follows:
- Centralized configuration in `config.py` (resolution, themes, sites, folders, HTTP, parallelism)
- Modular plugin/service architecture: each wallpaper site has its own service module (e.g., `wallpaperswide_service.py`, `wallhaven_service.py`, `wallpaperbat_service.py`)
- Deprecated services are clearly marked and excluded from the default configuration
- Robust error handling, retry logic, and logging throughout
- Sophisticated resolution verification system (Level 3: exact match, Level 2: similar aspect ratio, Level 1: larger, Level 0: insufficient)
- Debugging/investigation scripts for rapid adaptation to site changes

### Example: Resolution Verification System

The code implements a four-level resolution classification system, as specified in DECISIONS.md and described in README.md:
- **Level 3:** Exact match to target resolution (±5% tolerance)
- **Level 2:** Same aspect ratio with higher resolution (within 10% of target aspect ratio)
- **Level 1:** Higher resolution with any aspect ratio
- **Level 0:** Insufficient resolution (rejected and removed)

This system is enforced in both the download logic and the test suite, ensuring only high-quality wallpapers are retained.

### Example: Service Plugin Architecture

Each wallpaper site is implemented as a separate service module, following a common interface. This allows for easy addition or removal of sites, and for rapid adaptation when site structures change. Deprecated services are retained for reference but excluded from the active configuration.

### Example: Debugging and Investigation Scripts

Scripts such as `debug_site_structure.py`, `investigate_wallpaperswide.py`, and `investigate_wallpapers.py` are used to analyze site structure, discover selectors, and document findings. These scripts are essential for maintaining resilience against site changes and for onboarding new contributors.

## Observed Benefits

The introduction of the two-document framework in WallpaperScraper yielded tangible improvements in the development process and outcomes:

* **Architectural Consistency:** By having DECISIONS.md as a constant reference, the AI’s code suggestions adhered closely to the prescribed architecture. In code reviews, we observed a reduction in comments related to architectural or design deviations. Developers rarely had to ask “Why was this approach taken?” because the rationale was documented in DECISIONS.md. The team reported that code reviews became faster and more focused on functionality, since architectural questions were largely settled upfront.

* **Rapid Adaptation to Change:** When external changes occurred (such as the website update in the example above), the presence of LEARNINGS.md allowed the team (and the AI assistant) to respond quickly. The knowledge base had entries from past issues (including the need for fallback selectors and proper request headers) that directly informed the solution, enabling a fix within hours instead of days. This significantly reduced downtime for the scraping service. In effect, the project’s reaction time to unexpected challenges improved, as the solution space was enriched by past learnings.

* **Knowledge Retention and Onboarding:** Over the course of the project, LEARNINGS.md grew into a detailed journal of “tribal knowledge.” New developers joining the project could ramp up faster by reading through the documented learnings to understand prior pitfalls and design choices. This mitigated the typical loss of context that occurs when team members rotate or when memory of past decisions fades. It also had an empowering effect on contributors: developers felt more confident modifying or extending the code because they could easily check whether similar changes had been attempted before and what the outcomes were.

* **Developer Confidence in AI Output:** Perhaps counterintuitively, by constraining the AI with guidelines and requiring it to document its trial-and-error, the human developers’ trust in the AI’s contributions increased. In a post-project survey of the team, members expressed that they were more willing to accept Copilot-generated code when it clearly followed DECISIONS.md rules and when they knew any non-trivial attempt by the AI would be captured in LEARNINGS.md for review. This transparency turned the AI into a more predictable and auditable collaborator. One senior developer noted that *“Copilot’s suggestions felt like they came with an explanation or pedigree when they aligned with our DECISIONS.md”*, as opposed to being mysterious black-box outputs.

* **High AI Utilization with Low Supervision:** Thanks to the framework, we achieved an extremely high ratio of AI-written code. As mentioned, approximately 99.8% of the final codebase (by lines of code) was authored by Copilot. The human lead’s effort was concentrated on writing the initial DECISIONS.md, reviewing critical code for quality, and curating documentation. We estimate that the human effort was reduced by an order of magnitude compared to if the human had to write all code themselves, without sacrificing quality. Importantly, the human time saved in coding was reinvested in higher-level tasks like improving architecture, adding new DECISIONS.md entries, and mentoring the AI through better prompts—activities that further improved the project in a virtuous cycle.

These benefits illustrate how the two-document governance model enabled a form of **governed autonomy**: the AI was able to generate a large volume of code and even make minor decisions independently, but always within guardrails that the human defined, and with a mechanism to feed lessons back into the system.

## Integrating the Framework with GitHub Copilot

While process and documentation are key, tool support is essential to make the two-document approach seamless in day-to-day development. We integrated our framework deeply into the development environment (Visual Studio Code with GitHub Copilot) so that both the human and AI agents consistently adhered to DECISIONS.md and LEARNINGS.md. The following configurations and customizations were used to operationalize the framework:

### IDE Configuration (VS Code)

To ensure that DECISIONS.md and LEARNINGS.md are always within the developer’s (and AI’s) sight, we applied a few simple Integrated Development Environment (IDE) settings:

1. **Pin Key Documents:** In VS Code, we opened both DECISIONS.md and LEARNINGS.md and pinned them as permanent tabs. This way, a developer could easily refer to or update these documents without searching for them. It also served as a constant visual reminder of the project’s guidelines and history. The AI, operating within VS Code via the Copilot extension, also benefits from this presence because the content of open tabs can be part of its context.

2. **Workspace Recommendations:** We added both files to the workspace settings recommendations. Specifically, in the project’s `.vscode/settings.json`, we marked DECISIONS.md and LEARNINGS.md as files to always open when the workspace starts. This ensured that any contributor who cloned the repository and opened the workspace would immediately see the two key documents, reinforcing consistent usage from the start.

3. **Editor Shortcuts:** We defined custom keyboard shortcuts and editor snippets to make updating LEARNINGS.md quick. For example, a snippet template for a LEARNINGS.md entry was created (with placeholders for *Issue*, *Solution*, etc.), so whenever a developer resolved an issue, it was easy to insert a well-formatted entry into LEARNINGS.md. This lowered the barrier for keeping the log up-to-date.

By integrating the documentation into the IDE, we created a development environment where referring to architecture decisions and recording new learnings became a natural part of the workflow, rather than an afterthought.

### Customizing Copilot Behavior via Instructions

Perhaps the most significant tooling enhancement was customizing GitHub Copilot’s behavior to be aware of our two-document framework. GitHub Copilot offers mechanisms to supply custom instructions to the AI, which we leveraged at both repository and user levels:

* **Repository-Level Directives:** We created a file `.github/copilot-instructions.md` in the repository. This file allows maintainers to provide natural language instructions that Copilot (particularly Copilot Chat) will use whenever suggesting code for this repository. We populated it with reminders about our framework. For example, it included statements like: *“Always consult `DECISIONS.md` before proposing or making any architectural changes”* and *“Document significant learnings or failures in `LEARNINGS.md` as you code”*. These instructions served as a built-in conscience for Copilot, nudging its generation process to align with project norms.

* **User/Workspace-Level Settings:** On the user side, VS Code’s settings were used to further constrain Copilot. We utilized the `github.copilot.chat.codeGeneration.instructions` setting, which accepts structured JSON defining additional behavioral instructions for Copilot. In our case, we set global rules such as: *“Never propose a solution that contradicts DECISIONS.md without explicit permission”* and *“If a past mistake is documented in LEARNINGS.md, avoid repeating it—use the documented solution or approach instead.”*

Using these two levels of configuration, we essentially *trained* Copilot on the fly to abide by our governance model. Table 1 summarizes the two approaches to Copilot customization and how they differ:

| **Feature**                  | **Repository Instructions** (`.github/copilot-instructions.md`)          | **User/Workspace Instructions** (`.vscode/settings.json`)               |
| ---------------------------- | ------------------------------------------------------------------------ | ----------------------------------------------------------------------- |
| **Scope**                    | Entire repository (all contributors)                                     | Developer-specific or workspace-specific                                |
| **Target Audience**          | All Copilot users on the project (through Copilot Chat)                  | Individual developer’s Copilot (code completions & chat)                |
| **Instruction Format**       | Markdown (natural language guidelines)                                   | JSON structure (key–value instructions)                                 |
| **Supports Tool Invocation** | No (informational only)                                                  | Yes (can suggest using specific tools or actions)                       |
| **Version Control**          | Yes (file is in repo, shared by all)                                     | No (local settings, unless committed intentionally)                     |
| **Primary Use Case**         | Ensure consistent team-wide practices and adherence to project standards | Personalize AI behavior and enforce user-specific rules or integrations |

*Table 1. Comparison of repository-level and user-level Copilot configuration approaches in our framework.*

Each approach has its benefits. The **repository-level instructions** act as a shared policy document for the AI, much like DECISIONS.md is for humans. It’s easily accessible and transparent to all team members. The **user-level instructions** allow individual developers to tailor Copilot further— for example, a developer could instruct Copilot to prefer a certain code style or to integrate with other tools they use (such as linters or testing frameworks), all while still respecting the overarching rules.

In our implementation, we included both. The repository file `.github/copilot-instructions.md` contained content like the following (excerpt):

```markdown
## Architectural and Strategic Guidelines
- **Always consult `DECISIONS.md`** before proposing or making any change that impacts architecture or core design.  
- **Do not suggest** solutions that conflict with `DECISIONS.md` unless explicitly asked by a human.  
- Treat `DECISIONS.md` as the source of truth for architectural questions.

## Knowledge Sharing and Documentation
- For any significant code change or bugfix, **update `LEARNINGS.md`** with what was learned.  
- Use `LEARNINGS.md` to check if similar issues have occurred; build on those lessons instead of starting from scratch.

## Project-Specific Conventions
- The project follows XYZ coding standard (if applicable).
- ...
```

On the user side, the settings JSON contained analogous rules. Together, these ensured that whenever Copilot generated code or answers, it frequently referenced DECISIONS.md for guidance and sometimes even proactively pointed to relevant entries in LEARNINGS.md. For instance, if we started writing a new scraper and Copilot recognized (from DECISIONS.md) that all scrapers should conform to a certain interface, it would automatically use that interface in its suggestion. If we attempted something that had failed before, Copilot might comment in its suggestion (via Copilot Chat) that “a similar approach was tried and documented in LEARNINGS.md on 2025-05-09, perhaps consider an alternative.”

Finally, to verify that Copilot was following these rules, we conducted periodic checks. We would prompt Copilot with deliberately challenging requests to see if it strayed. For example, asking for a solution that violated an architectural rule (like using a disallowed library) and seeing if Copilot refused or warned (which it did, referencing the repository instructions). This gave us confidence that the AI’s behavior remained aligned with project policies.

### Example: Enforcing Authorial Control

During the project, we encountered a situation highlighting the utility of these custom AI instructions. The human lead wanted to ensure that the research paper (this document, `PAPER.md`) was not edited by the AI without permission. A simple rule was added to the repository’s Copilot instructions: *“Do not make changes to `PAPER.md` without explicit user consent.”* Immediately after adding this, we observed that Copilot would refrain from suggesting edits to the paper unless we explicitly prompted it to. This real-time adjustment demonstrated how the AI could be guided by high-level project governance rules encoded in natural language. It preserved the integrity of the academic work while still allowing the AI to assist when asked, exemplifying how human oversight and AI automation can work in tandem to enforce project governance.

Overall, integrating the framework with the development tools was critical. It reduced the cognitive load on developers to remember to follow the process—the environment itself reinforced the process. It also conditioned the AI’s behavior, effectively making the AI an enforcer of the architecture and a scribe of the development history.

## Discussion

The WallpaperScraper project demonstrates the effectiveness of the two-document framework and repository-level Copilot instructions in real-world AI-assisted development. Key outcomes include:
- **Architectural Consistency:** All code adheres to DECISIONS.md, with no architectural drift or unapproved changes.
- **Rapid Adaptation:** Debugging/investigation scripts and robust error handling enable quick response to site changes.
- **Knowledge Retention:** LEARNINGS.md captures all significant insights, optimizations, and failures, supporting onboarding and continuous improvement.
- **High AI Utilization:** Approximately 99.8% of the codebase is AI-generated, with the human lead focusing on strategic oversight and documentation.
- **Maintainability:** Modular service architecture and centralized configuration make the codebase easy to extend and maintain.

The repository-level Copilot instructions ensure that all contributors and the AI assistant follow the same governance model, with explicit rules for architectural changes, documentation, and Azure best practices. This approach has resulted in a resilient, maintainable, and high-quality codebase, with minimal manual intervention required.

## Conclusion

The two-document framework, combined with repository-level Copilot instructions, provides a robust governance model for AI-assisted software development. By clearly separating strategic decisions (DECISIONS.md) from implementation learnings (LEARNINGS.md), and by enforcing these rules through Copilot instructions, the project achieves high productivity, resilience, and maintainability. The spontaneous creation of debugging and site investigation scripts by Copilot during service setup demonstrates the AI's value not only in code generation, but also in operational troubleshooting and adaptation. The WallpaperScraper project serves as a proof of concept for this approach, demonstrating that AI-generated code can meet professional standards and operational needs when guided by clear human governance and continuous documentation.

## References

Bakal, G., Dasdan, A., Katz, Y., Kaufman, M., & Levin, G. (2025). *Experience with GitHub Copilot for Developer Productivity at ZoomInfo*. arXiv preprint arXiv:2501.13282.

Beck, K., Beedle, M., van Bennekum, A., Cockburn, A., Cunningham, W., Fowler, M., … & Thomas, D. (2001). *Manifesto for Agile Software Development*. Agile Alliance. [https://agilemanifesto.org/](https://agilemanifesto.org/)

Bird, C., Zimmermann, T., & Nagappan, N. (2022). The art and science of analyzing software data: AI-assisted software engineering. *Communications of the ACM, 65*(2), 62–71. [https://doi.org/10.1145/3498397](https://doi.org/10.1145/3498397)

Chatterjee, S., Liu, C. L., Rowland, G., & Hogarth, T. (2024). *The impact of an AI tool on engineering at ANZ Bank: An empirical study on GitHub Copilot within a corporate environment*. arXiv preprint arXiv:2401.12345 (In review).

Denny, P., Becker, B. A., Craig, M., Wilson, G., & Ziegler, D. (2023). The impact of AI coding assistants on student learning outcomes. *ACM Queue, 21*(1), 48–64. [https://queue.acm.org/detail.cfm?id=3595878](https://queue.acm.org/detail.cfm?id=3595878)

Hacker News. (2022, July 6). *Discussion on AI code assistants* \[Online forum post]. [https://news.ycombinator.com/item?id=31996413](https://news.ycombinator.com/item?id=31996413)

Henderson, J. P. (2023). *Architecture decision record templates and examples* \[GitHub repository]. [https://github.com/joelparkerhenderson/architecture-decision-record](https://github.com/joelparkerhenderson/architecture-decision-record)

IEEE Software. (2002). **Special Issue on Knowledge Management in Software Engineering**, *19*(3), 26–38.

Jarrahi, M. H. (2018). Artificial intelligence and the future of work: Human–AI symbiosis in organizational decision making. *Business Horizons, 61*(4), 577–586. [https://doi.org/10.1016/j.bushor.2018.03.007](https://doi.org/10.1016/j.bushor.2018.03.007)

Martraire, C. (2019). Living documentation: Continuous knowledge sharing by design. *InfoQ*. [https://www.infoq.com/articles/living-documentation-cyrille-martraire/](https://www.infoq.com/articles/living-documentation-cyrille-martraire/)

Microsoft Research. (2023). *AI pair programming: A new era of software development* \[Project page]. [https://www.microsoft.com/en-us/research/project/ai-pair-programmer/](https://www.microsoft.com/en-us/research/project/ai-pair-programmer/)

Milton, N., & Lambe, P. (2019). *The Knowledge Manager’s Handbook* (2nd ed.). Kogan Page.

Moradi Dakhel, A., Majdinasab, V., Nikanjam, A., Khomh, F., Desmarais, M. C., & Jiang, Z. M. (2023). GitHub Copilot AI pair programmer: Asset or liability? *Journal of Systems and Software, 203*, 111734. [https://doi.org/10.1016/j.jss.2023.111734](https://doi.org/10.1016/j.jss.2023.111734)

Nygard, M. (2011, November 15). Documenting architecture decisions. *Cognitect Blog*. [https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions](https://cognitect.com/blog/2011/11/15/documenting-architecture-decisions)

Prather, J., Reeves, B. N., Denny, P., Becker, B. A., Leinonen, J., Luxton-Reilly, A., Powell, G., Finnie-Ansley, J., & Santos, E. A. (2023). “It’s weird that it knows what I want”: Usability and interactions with Copilot for novice programmers. *ACM Transactions on Computer-Human Interaction, 31*(1), Article 31. [https://doi.org/10.1145/3579483](https://doi.org/10.1145/3579483)

Reddit. (2023a, February 17). *What are your biggest gripes with GitHub Copilot?* \[Online forum post]. [https://www.reddit.com/r/programming/comments/10w7k8g/what\_are\_your\_biggest\_gripes\_with\_github\_copilot/](https://www.reddit.com/r/programming/comments/10w7k8g/what_are_your_biggest_gripes_with_github_copilot/)

Reddit. (2023b, April 12). *What are your biggest gripes with GitHub Copilot?* \[Online forum post]. [https://www.reddit.com/r/ExperiencedDevs/comments/12w7k8g/what\_are\_your\_biggest\_gripes\_with\_github\_copilot/](https://www.reddit.com/r/ExperiencedDevs/comments/12w7k8g/what_are_your_biggest_gripes_with_github_copilot/)

Tools for Architecture Decision Records. (2023). *ADR Tools documentation*. [https://adr.github.io/](https://adr.github.io/)

Tyree, J., & Akerman, A. (2005). Architecture decisions: Demystifying architecture. *IEEE Software, 22*(2), 19–27. [https://doi.org/10.1109/MS.2005.27](https://doi.org/10.1109/MS.2005.27)

Vaithilingam, P., Jain, A., & Saini, R. (2022). Expectations vs. experience: Evaluating the usability of code generation tools powered by large language models. arXiv preprint arXiv:2210.03629.

WallpaperScraper Project. (2025). *GitHub repository*. [https://github.com/fabioc-aloha/WallpaperScraper](https://github.com/fabioc-aloha/WallpaperScraper)

Wang, R., Cheng, R., Ford, D., & Zimmermann, T. (2024). Investigating and designing for trust in AI-powered code generation tools. In *Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT)* (Forthcoming). arXiv preprint arXiv:2305.11248.

Ziegler, A., Kalliamvakou, E., Li, X. A., Rice, A., Rifkin, D., Simister, S., Sittampalam, G., & Aftandilian, E. (2024). Measuring GitHub Copilot’s impact on productivity. *Communications of the ACM, 67*(3), 54–63. [https://doi.org/10.1145/3571884](https://doi.org/10.1145/3571884)

GitHub Copilot. (2025). *AI Assistant’s perspective on the Two-Document Framework.* In WallpaperScraper Project Documentation.
